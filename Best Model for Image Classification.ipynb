{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# import tensorflow.keras\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix , classification_report, accuracy_score, precision_score, recall_score,f1_score\n",
    "import seaborn as sns\n",
    "from keras_tuner import RandomSearch\n",
    "from keras_tuner.engine.hyperparameters import HyperParameters\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import to_categorical\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images in X_train = 50000\n",
      "Number of images in X_test = 10000\n",
      "Shape of X_train = (50000, 32, 32, 3)\n",
      "Shape of y_train = (50000, 1)\n"
     ]
    }
   ],
   "source": [
    "# Dataset\n",
    "(X_train, y_train), (X_test, y_test) = datasets.cifar10.load_data()\n",
    "print(f'Number of images in X_train = {X_train.shape[0]}')\n",
    "print(f'Number of images in X_test = {X_test.shape[0]}')\n",
    "print(f'Shape of X_train = {X_train.shape}')\n",
    "print(f'Shape of y_train = {y_train.shape}')\n",
    "y_train = y_train.reshape(-1,)  # to flatten the array of classes of images\n",
    "classes = [\"airplane\", \"automobile\", \"bird\", \"cat\",\n",
    "           \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n",
    "\n",
    "\n",
    "def showImage(X, y, index):\n",
    "    plt.figure(figsize=(3, 3))\n",
    "    plt.imshow(X[index])\n",
    "    plt.xlabel(classes[y[index]])\n",
    "\n",
    "\n",
    "def showImages(X, y, index1, index2):\n",
    "    for i in range(index1, index2+1):\n",
    "        plt.figure(figsize=(3, 3))\n",
    "        plt.imshow(X[i])\n",
    "        plt.xlabel(classes[y[i]])\n",
    "\n",
    "\n",
    "# Data Normalization\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0\n",
    "\n",
    "\n",
    "def y_pred_classes(y_pred):\n",
    "    y_pred_classes_ = np.array([np.argmax(element) for element in y_pred])\n",
    "    return y_pred_classes_\n",
    "\n",
    "\n",
    "def plot_CM():\n",
    "    cm = confusion_matrix(y_pred=y_pred_classes(), y_true=y_test)\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=classes, yticklabels=classes)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Confusion Matrix using ANN')\n",
    "    plt.show()\n",
    "\n",
    "def plot_classification_report():\n",
    "    print(\"Classification Report: \\n\", classification_report(y_test, y_pred_classes()))\n",
    "def goodness(y_pred, y_true):\n",
    "    print(f\"Precision is {precision_score(y_true=y_true,y_pred=y_pred)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Hot Encoding\n",
    "y_train_ = to_categorical(y_train)\n",
    "y_test_ = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn8=models.Sequential([\n",
    "\n",
    "    layers.Conv2D(filters=64,kernel_size=(3,3),activation='relu', input_shape=(32,32,3)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Conv2D(filters=64,kernel_size=(3,3),activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.25),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "\n",
    "    layers.Conv2D(filters=128,kernel_size=(3,3),activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Conv2D(filters=128,kernel_size=(3,3),activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.25),\n",
    "    layers.Flatten(),\n",
    "\n",
    "    # layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "cnn8.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "cnn8.fit(X_train, y_train, epochs=25)\n",
    "cnn8.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\devba\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "cnn8.save(\"cnn8.h5\")\n",
    "cnn8.save(\"cnn8.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "1563/1563 [==============================] - 226s 144ms/step - loss: 2.4113 - accuracy: 0.4087\n",
      "Epoch 2/25\n",
      "1563/1563 [==============================] - 239s 153ms/step - loss: 1.4292 - accuracy: 0.5656\n",
      "Epoch 3/25\n",
      "1563/1563 [==============================] - 239s 153ms/step - loss: 0.9831 - accuracy: 0.6636\n",
      "Epoch 4/25\n",
      "1563/1563 [==============================] - 239s 153ms/step - loss: 0.7928 - accuracy: 0.7256\n",
      "Epoch 5/25\n",
      "1563/1563 [==============================] - 240s 154ms/step - loss: 0.6914 - accuracy: 0.7578\n",
      "Epoch 6/25\n",
      "1563/1563 [==============================] - 240s 153ms/step - loss: 0.6059 - accuracy: 0.7894\n",
      "Epoch 7/25\n",
      "1563/1563 [==============================] - 241s 154ms/step - loss: 0.5355 - accuracy: 0.8121\n",
      "Epoch 8/25\n",
      "1563/1563 [==============================] - 228s 146ms/step - loss: 0.4739 - accuracy: 0.8340\n",
      "Epoch 9/25\n",
      "1563/1563 [==============================] - 235s 150ms/step - loss: 0.4172 - accuracy: 0.8528\n",
      "Epoch 10/25\n",
      "1563/1563 [==============================] - 237s 151ms/step - loss: 0.3655 - accuracy: 0.8718\n",
      "Epoch 11/25\n",
      "1563/1563 [==============================] - 240s 154ms/step - loss: 0.3214 - accuracy: 0.8870\n",
      "Epoch 12/25\n",
      "1563/1563 [==============================] - 240s 154ms/step - loss: 0.2812 - accuracy: 0.8990\n",
      "Epoch 13/25\n",
      "1563/1563 [==============================] - 241s 154ms/step - loss: 0.2463 - accuracy: 0.9135\n",
      "Epoch 14/25\n",
      "1563/1563 [==============================] - 235s 150ms/step - loss: 0.2265 - accuracy: 0.9205\n",
      "Epoch 15/25\n",
      "1563/1563 [==============================] - 187s 120ms/step - loss: 0.2067 - accuracy: 0.9276\n",
      "Epoch 16/25\n",
      "1563/1563 [==============================] - 191s 122ms/step - loss: 0.1930 - accuracy: 0.9321\n",
      "Epoch 17/25\n",
      "1563/1563 [==============================] - 190s 121ms/step - loss: 0.1737 - accuracy: 0.9388\n",
      "Epoch 18/25\n",
      "1563/1563 [==============================] - 432s 276ms/step - loss: 0.1656 - accuracy: 0.9420\n",
      "Epoch 19/25\n",
      "1563/1563 [==============================] - 175s 112ms/step - loss: 0.1557 - accuracy: 0.9454\n",
      "Epoch 20/25\n",
      "1563/1563 [==============================] - 223s 143ms/step - loss: 0.1450 - accuracy: 0.9491\n",
      "Epoch 21/25\n",
      "1563/1563 [==============================] - 271s 174ms/step - loss: 0.1411 - accuracy: 0.9499\n",
      "Epoch 22/25\n",
      "1563/1563 [==============================] - 271s 173ms/step - loss: 0.1275 - accuracy: 0.9549\n",
      "Epoch 23/25\n",
      "1563/1563 [==============================] - 264s 169ms/step - loss: 0.1255 - accuracy: 0.9563\n",
      "Epoch 24/25\n",
      "1563/1563 [==============================] - 258s 165ms/step - loss: 0.1195 - accuracy: 0.9585\n",
      "Epoch 25/25\n",
      "1563/1563 [==============================] - 256s 164ms/step - loss: 0.1165 - accuracy: 0.9592\n",
      "313/313 [==============================] - 14s 43ms/step - loss: 0.9797 - accuracy: 0.7851\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9797337651252747, 0.785099983215332]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn9=models.Sequential([\n",
    "    layers.Conv2D(filters=64,kernel_size=(3,3),activation='relu', input_shape=(32,32,3)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Conv2D(filters=64,kernel_size=(3,3),activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.25),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "\n",
    "    layers.Conv2D(filters=128,kernel_size=(3,3),activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Conv2D(filters=128,kernel_size=(3,3),activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.25),\n",
    "\n",
    "    layers.Conv2D(filters=256,kernel_size=(3,3),activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Conv2D(filters=256,kernel_size=(3,3),activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.25),\n",
    "    layers.Flatten(),\n",
    "\n",
    "    # layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "cnn9.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "cnn9.fit(X_train, y_train, epochs=25)\n",
    "cnn9.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\devba\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "cnn9.save(\"cnn9.h5\")\n",
    "cnn9.save(\"cnn9.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
